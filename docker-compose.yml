# ----------------------------------------------------------------------------------------
# -- Docs: https://github.com/cluster-apps-on-docker/spark-standalone-cluster-on-docker --
#
#   Jupyter notebook - http://localhost:8888
#   HUE Desktop      - http://localhost:8890
#   Namenode         - http://localhost:50070
#   Datanode         - http://localhost:50075
#   Hive Server      - http://localhost:10000
#   Spark Master     - http://localhost:8080
#   Hive Server      - http://localhost:10000
#   Livy Server      - http://localhost:8998 - off for now, cannot marry dependencies
#   Spark Job Mgr    - http://localhost:4040
#
#
# ----------------------------------------------------------------------------------------
version: "3"
volumes:
  hadoop_namenode:
  hadoop_datanode:
  hadoop_historyserver:
  hue_data:

services:

  #
  # HADOOP & HIVE
  #
  namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
    container_name: hadoop-namenode
    hostname: namenode.local
    restart: always
    ports:
      - 9870:9870
      - 9000:9000
    volumes:
      - hadoop_namenode:/hadoop/dfs/name
    environment:
      - CLUSTER_NAME=sandbox
    env_file:
      - ./hadoop-hive.env
    networks:
      - localnet

  datanode:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: hadoop-datanode
    hostname: datanode.local
    restart: always
    ports:
      - 9864:9864
    volumes:
      - hadoop_datanode:/hadoop/dfs/data
    environment:
      SERVICE_PRECONDITION: "namenode:9870"
    env_file:
      - ./hadoop-hive.env
    networks:
      - localnet

  resourcemanager:
    image: bde2020/hadoop-resourcemanager:2.0.0-hadoop3.2.1-java8
    container_name: hadoop-resourcemanager
    restart: always
    ports:
      - 8088:8088
      - 8030:8030
      - 8031:8031
      - 8032:8032
    environment:
      SERVICE_PRECONDITION: "namenode:9870 datanode:9864"
    env_file:
      - ./hadoop-hive.env
    networks:
      - localnet

  nodemanager:
    image: bde2020/hadoop-nodemanager:2.0.0-hadoop3.2.1-java8
    container_name: hadoop-nodemanager
    restart: always
    environment:
      SERVICE_PRECONDITION: "namenode:9870 datanode:9864 resourcemanager:8088"
    env_file:
      - ./hadoop-hive.env
    networks:
      - localnet

  historyserver:
    image: bde2020/hadoop-historyserver:2.0.0-hadoop3.2.1-java8
    container_name: hadoop-historyserver
    restart: always
    ports:
      - 8188:8188
    environment:
      SERVICE_PRECONDITION: "namenode:9870 datanode:9864 resourcemanager:8088"
    volumes:
      - hadoop_historyserver:/hadoop/yarn/timeline
    env_file:
      - ./hadoop-hive.env
    networks:
      - localnet

  # Hive SQL frontend to Hadoop and spark
  hive-server:
    image: bde2020/hive:2.3.2-postgresql-metastore
    container_name: hive-server
    hostname: hive-server
    env_file:
      - ./hadoop-hive.env
    environment:
      HIVE_CORE_CONF_javax_jdo_option_ConnectionURL: "jdbc:postgresql://hive-metastore/metastore"
      SERVICE_PRECONDITION: "hive-metastore:9083"
    ports:
      - "9999:9999"
      - "10000:10000"
      - "10002:10002"
    networks:
      - localnet

  hive-metastore:
    image: bde2020/hive:2.3.2-postgresql-metastore
    container_name: hive-metastore
    hostname: hive-metastore
    env_file:
      - ./hadoop-hive.env
    command: /opt/hive/bin/hive --service metastore
    environment:
      SERVICE_PRECONDITION: "namenode:9870 datanode:9864 hive-metastore-postgresql:5432"
    ports:
      - "9083:9083"
    networks:
      - localnet

  hive-metastore-postgresql:
    image: bde2020/hive-metastore-postgresql:2.3.0
    container_name: hive-metastore-postgresql
    ports:
      - "5432"
    networks:
      - localnet

  # HUE frontend to hive and hadoop
  huedb:
    container_name: hue-db
    image: postgres:12.1-alpine
    volumes:
      - hue_data:/var/lib/postgressl/data/
    ports:
      - "5432"
    env_file:
      - ./hadoop-hive.env
    environment:
      SERVICE_PRECONDITION: "namenode:9870 datanode:9864 hive-metastore:9083"
    networks:
      - localnet

  hue:
    container_name: hue-server
    image: gethue/hue:latest
    environment:
        SERVICE_PRECONDITION: "namenode:9870 datanode:9864 hive-metastore:9083 huedb:5432"
    ports:
        - "8890:8888"
    volumes:
      - ./hue-overrides.ini:/usr/share/hue/desktop/conf/hue-overrides.ini
    links:
      - huedb
    networks:
      - localnet
  #
  # SPARK
  #
  # master and two workers
  # base image: bde2020/spark-master and bde2020/spark-worker
  # from bde2020. Livy Spark version requires 2.x
  # spark 3 image is commented out, uncomment to test
  # spark worker has the pyspark installed, but not R
  # spark has been updated to support R language
  spark-master:
    container_name: spark-master
    hostname: spark-master
    image: stellars/spark-master:3.1.1-hadoop3.2
    build:
       context: build
       dockerfile: spark-master.Dockerfile
    ports:
       - 7077:7077
       - 8080:8080
       # - 4040-4049:4040-4049
    volumes:
       - ./work:/opt/workspace
    networks:
       - localnet

  spark-worker-1:
    container_name: spark-worker-1
    hostname: spark-worker-1
    image: stellars/spark-worker:3.1.1-hadoop3.2
    build:
       context: build
       dockerfile: spark-worker.Dockerfile
    environment:
       - SPARK_WORKER_CORES=2
       - SPARK_WORKER_MEMORY=2g
       - SPARK_MASTER=spark://spark-master:7077
    ports:
       - 8081:8081
    volumes:
       - ./work:/opt/workspace
    depends_on:
       - spark-master
    networks:
       - localnet

  # spark http thrift server that offer HTTP RPC endpoint
  # used by many BI tools such as powerbi and tableau
  # and allows execution of the HIVE SQL with Spark workers
  # this server exposes http://localhost:10001/cliservice endpoint
  spark-sql-server:
    container_name: thrift-server
    hostname: thrift-server
    image: stellars/thrift-server:3.1.1-hadoop3.2
    build:
       context: build/thrift-http-server-docker
       dockerfile: Dockerfile
    environment:
       SPARK_MASTER: "spark://spark-master:7077"
       SERVICE_PRECONDITION: "hive-metastore:9083"
    env_file:
      - ./hadoop-hive.env
      - ./hadoop-hive-http.env
    ports:
       - "10001:10001"
    volumes:
       - ./work:/opt/workspace
    networks:
       - localnet

  # Livy provides REST API for Spark. The image below
  # livy image is an extension from https://github.com/cloudiator/livy-server-docker
  # image was rebuilt by stellars to support sparkr. Built on spark 2.4.8
  livy:
    image: stellars/livy-server-docker:spark2.4.8
    container_name: livy
    build:
       context: $PWD/build/livy-server-docker
       dockerfile: Dockerfile
    environment:
       # mode client or cluster
       - SPARK_MASTER_ENDPOINT=spark-master
       - SPARK_MASTER_PORT=7077
       - DEPLOY_MODE=client
    ports:
       - 8998:8998
       #- 4040:4040
    volumes:
       # directory to submit jars
       - $PWD/jars:/jars
    depends_on:
       - "spark-master"
       - "spark-worker-1"
    networks:
       - localnet

  # Jupyterlab has been rebuilt to use root account for simplicity
  # base image: jupyter/all-spark-notebook:spark-3.1.1
  jupyterlab:
    container_name: jupyter
    hostname: jupyter
    image: stellars/all-spark-notebook:spark-3.1.1
    build:
       context: build
       dockerfile: jupyter.Dockerfile
    container_name: jupyterlab
    environment:
      - JUPYTER_ENABLE_LAB=yes
    ports:
    ports:
      #- 4040:4040
      - 8888:8888
      #- 8889:8889
    working_dir: /opt/workspace
    volumes:
      - ./work:/opt/workspace
    command: start-notebook.sh --ip=0.0.0.0 --port=8888 --no-browser --allow-root --NotebookApp.token=
    networks:
      - localnet


networks:
    localnet:
